{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e29b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib2 import Request, urlopen\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "head = \"https://en.wikipedia.org/\"\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "job_titles = [\"solar+system\"]\n",
    "\n",
    "def get_soup(url):\n",
    "    \"\"\"\n",
    "    This function get the beautifulsoup object of a webpage.\n",
    "\n",
    "    Args:\n",
    "        url (str): the link string of webpage\n",
    "\n",
    "    Returns:\n",
    "        soup (obj): beautifulsoup object\n",
    "    \"\"\"\n",
    "    request = Request(url, headers={'User-Agent': 'Resistance is futile'})\n",
    "    response = urlopen(request)\n",
    "    return BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "def get_jobs_of_title(job_title):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        job_title (str): example: 'computer'\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "\n",
    "    #needed to be changed\n",
    "    num_pages = 1 #number of pages to scrape\n",
    "    page_gap_min = 3 #min sleep time between pages\n",
    "    page_gap_max = 5 #max sleep time between pages\n",
    "    job_per_page = 50 #number of jobs in one page\n",
    "    job_gap_min = 5 #min sleep time between jobs\n",
    "    job_gap_max = 6 #max sleep time between jobs\n",
    "\n",
    "    for i in range(num_pages): \n",
    "        #sleep between each call\n",
    "        gap = random.uniform(page_gap_min,page_gap_max) \n",
    "        time.sleep(gap)\n",
    "\n",
    "        #each page contains 50 jobs\n",
    "        tail = \"jobs?q={0}&sort=date&limit={1}\".format(job_title,job_per_page)\n",
    "        if i>0:\n",
    "            tail += \"&start={0}\".format(i*job_per_page)\n",
    "\n",
    "        #get link to joblist page\n",
    "        url = head+tail \n",
    "         \n",
    "        #get links to webpages of jobs on the joblist\n",
    "        job_page_links = get_job_links_from_page(url)\n",
    "\n",
    "        for job_page_link in job_page_links:\n",
    "            gap = random.uniform(job_gap_min,job_gap_max) \n",
    "            time.sleep(gap)\n",
    "            data = get_info_from_job_page(job_page_link)\n",
    "\n",
    "            print(json.dumps(data))\n",
    "\n",
    "def get_job_links_from_page(url):\n",
    "    \"\"\"\n",
    "    This function gets the links of the jobs on the joblist page.\n",
    "\n",
    "    Args:\n",
    "        url (str): link to joblist page\n",
    "\n",
    "    Returns:\n",
    "        job_page_links (list): list of links to the webpages of the jobs\n",
    "    \"\"\"\n",
    "\n",
    "    job_page_links = []\n",
    "    soup = get_soup(url)\n",
    "    for item in soup.find_all(\"a\", href=True):\n",
    "        if '/rc/clk?jk=' in str(item) and 'fccid=' in str(item):\n",
    "            link = item['href'].split(\"clk?\")[1]\n",
    "            job_page_links.append(head+'viewjob?'+link)\n",
    "    return job_page_links\n",
    "\n",
    "def get_info_from_job_page(url):\n",
    "    \"\"\"\n",
    "    This function get all the useful info from the job webpage.\n",
    "\n",
    "    Args:\n",
    "        url (str): link to job webpage\n",
    "\n",
    "    Returns:\n",
    "        data (dict): dictionary with keywords: \n",
    "                     time_stamp, original_link, job_title, location, company, description\n",
    "    \"\"\"\n",
    "    soup = get_soup(url)\n",
    "    data = {}\n",
    "    time_str = soup.find('div',class_='result-link-bar').find('span').getText()\n",
    "\n",
    "    try:\n",
    "        data[\"time_stamp\"] = get_timestamp(time_str).strftime(\"%d-%m-%Y %H:%M\")\n",
    "        data[\"job_title\"] = soup.find('b', class_='jobtitle').getText()\n",
    "        data[\"location\"] = soup.find('span', class_='location').getText()\n",
    "        data[\"company\"] = soup.find('span', class_='company').getText()\n",
    "        data[\"description\"] = soup.find('td',class_='snip').find('div').getText()\n",
    "\n",
    "        re_link = soup.find('a',class_='sl ws_label')['href'].split(\"&from=\")[0]\n",
    "        re_link = head[:-1]+re_link\n",
    "        data[\"original_link\"] = get_original_link(re_link)\n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "def get_timestamp(time_str):\n",
    "    \"\"\"\n",
    "    Calculate the timestamp from the time string.\n",
    "    \n",
    "    Args:\n",
    "        time_str (str): time string, like '2 hours ago'\n",
    "\n",
    "    Returns:\n",
    "        time_stamp (obj): timestamp object\n",
    "    \"\"\"\n",
    "    if 'hour' in time_str:\n",
    "        lag = int(time_str.split('hour')[0])\n",
    "        delta = timedelta(hours=lag)\n",
    "        now = datetime.utcnow().replace(second=0,minute=0)\n",
    "        return now-delta\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def get_original_link(url):\n",
    "    \"\"\"\n",
    "    Get the original link of the job description.\n",
    "    \n",
    "    Args:\n",
    "        url (str): the link in Indeed database\n",
    "\n",
    "    Returns:\n",
    "        url (str): the original link to the job description\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    original_url = driver.current_url\n",
    "    driver.quit()\n",
    "    return original_url\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_jobs_of_title(\"data+scientist\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
